# Algorithmic Recurrences
A recurrence T(n) is algorithmic if for every sufficiently large threshold constant n0 > 0:
For all n < n0, T(n) = Θ(1)
For all n >= n0, every path of recurrence eventually terminates in a defined base case.

Also we assume that the definition above is limited to values for which T(n) is defined.

The reason why the first property says that base cases must all run in constant time is:
First property says
0 < c1 <= T(n) < c2
Let c1 be the minimum amount of time it takes to call and return from a procedure (must be positive, since machine instructions must be evoked)
Let c2 be the maximum running time on any input size of n < n0 where n0 is large enough that there's at least one n smaller than n0 for the algorithm to solve

We will adopt the following convention:
Whenever a recurrence is stated without an explicit base case, we will assume that the recurrence is algorithmic.

Additionally asymptotic solutions of divide and conquer recurrences don't tend to change whenever we drop any floor or ceils (which we might do when converting an algorithm for use with ints to reals).

# Multiplying Square Matrices
Assume matrices are dense, so most of the entries are not 0 (because if they are then the matrix can be converted to a smaller one).

Matrix-Multiply procedure takes three inputs, A, B, and C, does this: C = C + A \* B. In the long run Matrix Multiplication dominates the cost of initializing C to 0s when we only want A \* B. 

```lua
MATRIX-MULTIPLY(A, B, C, n)
1 for i = 1 to n // compute entries in each of n rows
2    for j = 1 to n // compute n entries in row i
3		 for k = 1 to n
4			 cij = cij + aik * bkj // add in another term of equation (4.1)
```

Each nested loop runs n times, so $n^3$ in total.

# Divide and Conquer Matrices
Divide into four n/2 by n/2 matrices. For now assume n is a power of 2. Assume that C has been initialized to the zero matrix.

![[Pasted image 20240919193113.png]]

Two common approaches for matrix partitioning:
1. Allocate temp storage to hold A's four submatrices, B's four submatrices and copy from A and B. Then copy elements from C's submatrix to C. This takes Θ(n^2) time since there are 3n^2 copies.
2. Use index calculations, don't make any new arrays. Any changes are made within the original matrix.

We'll use index calculations and assume that matrix partitioning happens in Θ(1) time. 
```lua
MATRIX-MULTIPLY-RECURSIVE(A, B, C, n)
1 if n == 1
2 // Base case.
3 c11 = c11 + a11 * b11
4 return
5 // Divide.
6 partition A, B, and C into n=2  n=2 submatrices
A11, A12, A21, A22; B11, B12, B21, B22;
and C11, C12, C21, C22, respectively
7 // Conquer.
8 MATRIX-MULTIPLY-RECURSIVE (A11, B11, C11, n/2)
9 MATRIX-MULTIPLY-RECURSIVE (A11, B12, C12, n/2)
10 MATRIX-MULTIPLY-RECURSIVE (A21, B11, C21, n/2)
11 MATRIX-MULTIPLY-RECURSIVE (A21, B12, C22, n/2)
12 MATRIX-MULTIPLY-RECURSIVE (A12, B21, C11, n/2)
13 MATRIX-MULTIPLY-RECURSIVE (A12, B22, C12, n/2)
14 MATRIX-MULTIPLY-RECURSIVE (A22, B21, C21, n/2)
15 MATRIX-MULTIPLY-RECURSIVE (A22, B22, C22, n/2)
```
When n = 1, it just does scalar multiplication, which happens in constant time. Θ(1). We can omit this in the recurrence.

Recursive case occurs when n > 1. Since we make 8 calls, the first four being the first terms of each equation 4.5-4.8, and the next four computing the second terms and adding them to the first, T(n) = 8T(n / 2) + Θ(1). There is no combine step.

As we'll see from the master method, this has the solution T(n) = Θ($n^3$), which means that it still has the same running time as the normal matrix-multiply procedure.

The reason why this grows so much faster than merge sort even though this one has Θ(1) and merge sort has Θ(n) is because this has 8 * Θ(1) while merge sort has 2 * Θ(n).

(kind of obvious?)